"""
Enhanced Class-Level Discovery System

This module extends Level 2 composition with:
1. Advanced structural features (inheritance, composition, decorators)
2. Class-level discovery algorithm
3. Calibration framework for prediction accuracy

Goal: Prove class discovery works with same principles as function discovery
"""

import math
import os
import sys
from dataclasses import dataclass
from itertools import combinations
from typing import Dict, List, Optional, Tuple

# Add parent directory to path for imports
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

# Use unified harmonizer integration
from harmonizer_integration import HARMONIZER_AVAILABLE
from harmonizer_integration import PythonCodeHarmonizer as StringHarmonizer


@dataclass
class LJPWProfile:
    """Represents a 4D LJPW semantic profile."""

    L: float
    J: float
    P: float
    W: float

    def distance_to(self, other: "LJPWProfile") -> float:
        """Euclidean distance in 4D LJPW space."""
        return math.sqrt(
            (self.L - other.L) ** 2
            + (self.J - other.J) ** 2
            + (self.P - other.P) ** 2
            + (self.W - other.W) ** 2
        )

    def __repr__(self):
        return f"LJPW(L={self.L:.3f}, J={self.J:.3f}, P={self.P:.3f}, W={self.W:.3f})"


@dataclass
class ClassStructure:
    """
    Defines the structural features of a class.
    Each feature contributes to the emergent LJPW profile.
    """

    methods: List[str]
    has_init: bool = False
    has_state: bool = False
    has_history: bool = False
    parent_class: Optional[str] = None
    embedded_objects: List[str] = None  # Composition
    decorators: List[str] = None  # Method decorators
    has_properties: bool = False
    has_class_methods: bool = False
    has_abstract_methods: bool = False
    has_private_methods: bool = False

    def __post_init__(self):
        if self.embedded_objects is None:
            self.embedded_objects = []
        if self.decorators is None:
            self.decorators = []

    def structural_complexity(self) -> int:
        """Count number of structural features present."""
        count = 0
        if self.has_init:
            count += 1
        if self.has_state:
            count += 1
        if self.has_history:
            count += 1
        if self.parent_class:
            count += 1
        if self.embedded_objects:
            count += len(self.embedded_objects)
        if self.decorators:
            count += len(self.decorators)
        if self.has_properties:
            count += 1
        if self.has_class_methods:
            count += 1
        if self.has_abstract_methods:
            count += 1
        if self.has_private_methods:
            count += 1
        return count

    def __repr__(self):
        features = []
        if self.has_init:
            features.append("init")
        if self.has_state:
            features.append("state")
        if self.has_history:
            features.append("history")
        if self.parent_class:
            features.append(f"extends:{self.parent_class}")
        if self.embedded_objects:
            features.append(f"embeds:{','.join(self.embedded_objects)}")
        if self.decorators:
            features.append(f"decorators:{','.join(self.decorators)}")
        return f"Structure({len(self.methods)} methods, {', '.join(features)})"


# ==============================================================================
# Enhanced Method Library
# ==============================================================================

METHOD_LIBRARY = {
    # Secure methods (high Justice, high Love)
    "secure_add": '''
def secure_add(self, a, b):
    """Validated addition with logging."""
    if not isinstance(a, (int, float)) or not isinstance(b, (int, float)):
        raise TypeError("Inputs must be numeric")
    result = a + b
    print(f"[LOG] secure_add({a}, {b}) = {result}")
    return result
''',
    "secure_subtract": '''
def secure_subtract(self, a, b):
    """Validated subtraction with logging."""
    if not isinstance(a, (int, float)) or not isinstance(b, (int, float)):
        raise TypeError("Inputs must be numeric")
    result = a - b
    print(f"[LOG] secure_subtract({a}, {b}) = {result}")
    return result
''',
    "secure_multiply": '''
def secure_multiply(self, a, b):
    """Validated multiplication with logging."""
    if not isinstance(a, (int, float)) or not isinstance(b, (int, float)):
        raise TypeError("Inputs must be numeric")
    result = a * b
    print(f"[LOG] secure_multiply({a}, {b}) = {result}")
    return result
''',
    "secure_divide": '''
def secure_divide(self, a, b):
    """Validated division with zero-check and logging."""
    if not isinstance(a, (int, float)) or not isinstance(b, (int, float)):
        raise TypeError("Inputs must be numeric")
    if b == 0:
        raise ValueError("Cannot divide by zero")
    result = a / b
    print(f"[LOG] secure_divide({a}, {b}) = {result}")
    return result
''',
    # Simple methods (high Power, low Justice/Love)
    "simple_add": '''
def simple_add(self, a, b):
    """Direct addition."""
    return a + b
''',
    "simple_subtract": '''
def simple_subtract(self, a, b):
    """Direct subtraction."""
    return a - b
''',
    "simple_multiply": '''
def simple_multiply(self, a, b):
    """Direct multiplication."""
    return a * b
''',
    "simple_divide": '''
def simple_divide(self, a, b):
    """Direct division."""
    return a / b
''',
    # Utility methods (high Wisdom)
    "format_result": '''
def format_result(self, value, precision=2):
    """Format numerical result with specified precision."""
    return f"{{:.{{precision}}f}}".format(value, precision=precision)
''',
    "validate_input": '''
def validate_input(self, value):
    """Validate that input is numeric."""
    if not isinstance(value, (int, float)):
        raise TypeError(f"Expected numeric type, got {{type(value).__name__}}")
    return True
''',
    "log_operation": '''
def log_operation(self, operation, *args):
    """Log an operation to history."""
    if hasattr(self, 'history'):
        self.history.append({{
            'operation': operation,
            'args': args,
            'timestamp': __import__('time').time()
        }})
''',
}


# ==============================================================================
# Enhanced Class Composition Engine
# ==============================================================================


class EnhancedClassComposer:
    """
    Composes classes with advanced structural features.
    """

    @staticmethod
    def generate_class(name: str, structure: ClassStructure, method_sources: Dict[str, str]) -> str:
        """Generate Python class code from structure specification."""
        code = []

        # Parent class
        if structure.parent_class:
            code.append(f"class {name}({structure.parent_class}):")
        else:
            code.append(f"class {name}:")

        # Docstring
        code.append('    """')
        code.append(f"    {name} - Generated class")
        code.append(f'    Methods: {", ".join(structure.methods)}')
        if structure.parent_class:
            code.append(f"    Extends: {structure.parent_class}")
        if structure.embedded_objects:
            code.append(f'    Composes: {", ".join(structure.embedded_objects)}')
        code.append('    """')
        code.append("")

        # __init__ method
        if (
            structure.has_init
            or structure.has_state
            or structure.has_history
            or structure.embedded_objects
        ):
            code.append("    def __init__(self):")

            # Parent init
            if structure.parent_class:
                code.append("        super().__init__()")

            # State
            if structure.has_state:
                code.append("        self.precision = 10  # Calculation precision")
                code.append("        self.debug_mode = False  # Debug flag")

            # History
            if structure.has_history:
                code.append("        self.history = []  # Operation history")

            # Embedded objects (composition)
            for obj_name in structure.embedded_objects:
                code.append(f"        self.{obj_name} = None  # Embedded: {obj_name}")

            code.append("")

        # Properties
        if structure.has_properties:
            code.append("    @property")
            code.append("    def last_result(self):")
            code.append('        """Get the last operation result from history."""')
            code.append('        if hasattr(self, "history") and self.history:')
            code.append('            return self.history[-1].get("result")')
            code.append("        return None")
            code.append("")

        # Class methods
        if structure.has_class_methods:
            code.append("    @classmethod")
            code.append("    def create_default(cls):")
            code.append('        """Factory method to create instance with defaults."""')
            code.append("        return cls()")
            code.append("")

        # Abstract methods
        if structure.has_abstract_methods:
            code.append("    def compute(self, *args):")
            code.append('        """Abstract method for computation - override in subclass."""')
            code.append('        raise NotImplementedError("Subclass must implement compute()")')
            code.append("")

        # Regular methods
        for method_name in structure.methods:
            if method_name not in method_sources:
                continue

            method_code = method_sources[method_name].strip()

            # Apply decorators
            if structure.decorators:
                for decorator in structure.decorators:
                    code.append(f"    @{decorator}")

            # Add method (already has self parameter)
            for line in method_code.split("\n"):
                code.append("    " + line if line.strip() else "")

            code.append("")

        # Private helper methods
        if structure.has_private_methods:
            code.append("    def _internal_validate(self, value):")
            code.append('        """Private validation helper."""')
            code.append("        return isinstance(value, (int, float))")
            code.append("")

        return "\n".join(code)


# ==============================================================================
# Enhanced Composition Rule Engine
# ==============================================================================


class EnhancedCompositionRules:
    """
    Predicts emergent LJPW profile based on class structure.

    Model v2 - Extended Structural Features:
    - Base: Aggregation of method profiles
    - Bonuses: Structural features contribute to specific dimensions
    - Coupling: Features amplify each other
    - Calibration: Tunable coefficients
    """

    def __init__(self, method_profiles: Dict[str, LJPWProfile], calibration: Optional[Dict] = None):
        self.method_profiles = method_profiles

        # Default calibration coefficients (can be tuned)
        self.coeffs = calibration or {
            # Structural bonuses
            "state_wisdom": 0.20,
            "history_love": 0.20,
            "init_justice": 0.10,
            "inheritance_wisdom": 0.15,
            "composition_wisdom": 0.12,  # Per embedded object
            "decorators_love": 0.08,  # Per decorator
            "properties_wisdom": 0.10,
            "class_methods_wisdom": 0.08,
            "abstract_justice": 0.12,
            "private_justice": 0.08,
            # Diversity bonuses
            "method_diversity_wisdom": 0.10,  # For 4+ methods
            "structural_diversity_wisdom": 0.12,  # For 3+ structural features
            # Harmony bonuses
            "harmony_boost": 0.05,  # When 2+ major features
            "full_feature_boost": 0.08,  # When 4+ features
        }

    def predict_profile(self, structure: ClassStructure) -> LJPWProfile:
        """
        Predict emergent LJPW profile of a class.

        Returns predicted profile based on:
        1. Method aggregation (base)
        2. Structural bonuses
        3. Coupling effects
        4. Harmony boosts
        """
        # Base: Aggregate method profiles
        L, J, P, W = self._aggregate_methods(structure.methods)

        # Structural bonuses
        if structure.has_state:
            W = min(W + self.coeffs["state_wisdom"], 1.0)

        if structure.has_history:
            L = min(L + self.coeffs["history_love"], 1.0)

        if structure.has_init:
            J = min(J + self.coeffs["init_justice"], 1.0)

        if structure.parent_class:
            W = min(W + self.coeffs["inheritance_wisdom"], 1.0)
            # TODO: Could add parent class profile contribution

        if structure.embedded_objects:
            bonus = len(structure.embedded_objects) * self.coeffs["composition_wisdom"]
            W = min(W + bonus, 1.0)

        if structure.decorators:
            bonus = len(structure.decorators) * self.coeffs["decorators_love"]
            L = min(L + bonus, 1.0)

        if structure.has_properties:
            W = min(W + self.coeffs["properties_wisdom"], 1.0)

        if structure.has_class_methods:
            W = min(W + self.coeffs["class_methods_wisdom"], 1.0)

        if structure.has_abstract_methods:
            J = min(J + self.coeffs["abstract_justice"], 1.0)

        if structure.has_private_methods:
            J = min(J + self.coeffs["private_justice"], 1.0)

        # Diversity bonuses
        if len(structure.methods) >= 4:
            W = min(W + self.coeffs["method_diversity_wisdom"], 1.0)

        if structure.structural_complexity() >= 3:
            W = min(W + self.coeffs["structural_diversity_wisdom"], 1.0)

        # Harmony effects
        major_features = sum(
            [
                structure.has_state,
                structure.has_history,
                bool(structure.parent_class),
                bool(structure.embedded_objects),
                structure.has_properties,
            ]
        )

        if major_features >= 2:
            boost = self.coeffs["harmony_boost"]
            L = min(L + boost, 1.0)
            J = min(J + boost, 1.0)
            W = min(W + boost, 1.0)

        if major_features >= 4:
            boost = self.coeffs["full_feature_boost"]
            L = min(L + boost, 1.0)
            J = min(J + boost, 1.0)
            P = min(P + boost, 1.0)
            W = min(W + boost, 1.0)

        return LJPWProfile(L, J, P, W)

    def _aggregate_methods(self, methods: List[str]) -> Tuple[float, float, float, float]:
        """Aggregate method profiles into class base profile."""
        if not methods:
            return 0.0, 0.0, 0.0, 0.0

        L_sum, J_sum, P_sum, W_sum = 0.0, 0.0, 0.0, 0.0
        count = 0

        for method in methods:
            if method in self.method_profiles:
                profile = self.method_profiles[method]
                L_sum += profile.L
                J_sum += profile.J
                P_sum += profile.P
                W_sum += profile.W
                count += 1

        if count == 0:
            return 0.0, 0.0, 0.0, 0.0

        # Simple average (could be weighted in future)
        return (L_sum / count, J_sum / count, P_sum / count, W_sum / count)


# ==============================================================================
# Class-Level Discovery Engine
# ==============================================================================


class ClassDiscoveryEngine:
    """
    Searches for optimal class structures to match target LJPW profiles.

    Analogous to function-level discovery (Experiment C), but at class level.
    """

    def __init__(
        self,
        method_profiles: Dict[str, LJPWProfile],
        rule_engine: EnhancedCompositionRules,
        available_methods: List[str],
    ):
        self.method_profiles = method_profiles
        self.rule_engine = rule_engine
        self.available_methods = available_methods

    def search(
        self,
        target_profile: LJPWProfile,
        min_methods: int = 2,
        max_methods: int = 6,
        allow_structural_features: bool = True,
        top_k: int = 5,
    ) -> List[Tuple[ClassStructure, LJPWProfile, float]]:
        """
        Search for class structures that match target profile.

        Search space:
        - Method combinations (2-6 methods)
        - Structural feature combinations
        - Predict profile for each
        - Rank by distance to target

        Returns:
            List of (structure, predicted_profile, distance) tuples
        """
        print(f"\n[CLASS DISCOVERY] Searching for class matching: {target_profile}")
        print(f"  Available methods: {len(self.available_methods)}")
        print(f"  Method range: {min_methods}-{max_methods}")
        print(f"  Structural features: {'enabled' if allow_structural_features else 'disabled'}")

        candidates = []

        # Generate method combinations
        for num_methods in range(min_methods, max_methods + 1):
            for method_combo in combinations(self.available_methods, num_methods):
                method_list = list(method_combo)

                # Generate structural variants
                if allow_structural_features:
                    structures = self._generate_structural_variants(method_list)
                else:
                    structures = [ClassStructure(methods=method_list)]

                for structure in structures:
                    predicted = self.rule_engine.predict_profile(structure)
                    distance = predicted.distance_to(target_profile)
                    candidates.append((structure, predicted, distance))

        # Sort by distance
        candidates.sort(key=lambda x: x[2])

        print(f"  Generated {len(candidates)} candidate structures")
        print(f"  Returning top {top_k}")

        return candidates[:top_k]

    def _generate_structural_variants(self, methods: List[str]) -> List[ClassStructure]:
        """
        Generate structural feature variants for a method set.

        Strategy: Don't combinatorially explode - generate sensible combinations
        """
        variants = []

        # Base: No features
        variants.append(ClassStructure(methods=methods))

        # Simple features
        variants.append(ClassStructure(methods=methods, has_init=True))
        variants.append(ClassStructure(methods=methods, has_state=True, has_init=True))
        variants.append(ClassStructure(methods=methods, has_history=True, has_init=True))

        # Combined features
        variants.append(
            ClassStructure(methods=methods, has_state=True, has_history=True, has_init=True)
        )

        # With properties
        if len(methods) >= 3:
            variants.append(
                ClassStructure(methods=methods, has_state=True, has_properties=True, has_init=True)
            )

        # Full featured
        if len(methods) >= 4:
            variants.append(
                ClassStructure(
                    methods=methods,
                    has_state=True,
                    has_history=True,
                    has_properties=True,
                    has_private_methods=True,
                    has_init=True,
                )
            )

        return variants


# ==============================================================================
# Calibration Framework
# ==============================================================================


class CalibrationFramework:
    """
    Calibrates prediction model against actual measurements.

    Compares predicted vs actual LJPW profiles to tune coefficients.
    """

    def __init__(self, composer: EnhancedClassComposer, harmonizer: StringHarmonizer):
        self.composer = composer
        self.harmonizer = harmonizer

    def measure_actual_profile(self, class_code: str) -> Optional[LJPWProfile]:
        """Measure actual LJPW profile by analyzing generated code."""
        report = self.harmonizer.analyze_file_content(class_code)

        if not report:
            return None

        # Aggregate all methods in the class
        L_sum, J_sum, P_sum, W_sum = 0.0, 0.0, 0.0, 0.0
        count = 0

        for _method_name, analysis in report.items():
            coords = analysis["ice_result"]["ice_components"]["intent"].coordinates
            L_sum += coords.love
            J_sum += coords.justice
            P_sum += coords.power
            W_sum += coords.wisdom
            count += 1

        if count == 0:
            return None

        return LJPWProfile(L=L_sum / count, J=J_sum / count, P=P_sum / count, W=W_sum / count)

    def calibrate(
        self,
        test_structures: List[ClassStructure],
        method_sources: Dict[str, str],
        rule_engine: EnhancedCompositionRules,
    ) -> Dict[str, float]:
        """
        Calibrate coefficients by comparing predictions vs actuals.

        Returns:
            Dictionary of prediction errors and suggested adjustments
        """
        print("\n[CALIBRATION] Measuring prediction accuracy...")

        results = []

        for structure in test_structures:
            # Generate class
            class_code = self.composer.generate_class(
                name="TestClass", structure=structure, method_sources=method_sources
            )

            # Predict
            predicted = rule_engine.predict_profile(structure)

            # Measure actual
            actual = self.measure_actual_profile(class_code)

            if actual:
                error = predicted.distance_to(actual)
                results.append(
                    {
                        "structure": structure,
                        "predicted": predicted,
                        "actual": actual,
                        "error": error,
                    }
                )

                print(f"\n  Structure: {structure}")
                print(f"    Predicted: {predicted}")
                print(f"    Actual:    {actual}")
                print(f"    Error:     {error:.4f}")

        # Calculate summary statistics
        if results:
            avg_error = sum(r["error"] for r in results) / len(results)
            max_error = max(r["error"] for r in results)
            min_error = min(r["error"] for r in results)

            print("\n  Summary:")
            print(f"    Average error: {avg_error:.4f}")
            print(f"    Max error:     {max_error:.4f}")
            print(f"    Min error:     {min_error:.4f}")

            return {
                "avg_error": avg_error,
                "max_error": max_error,
                "min_error": min_error,
                "results": results,
            }

        return {"avg_error": float("inf"), "results": []}


# ==============================================================================
# Experiment Runner
# ==============================================================================


def run_enhanced_experiments():
    """
    Run comprehensive class-level discovery experiments.

    Tests:
    1. Discovery with different target profiles
    2. Structural feature impact
    3. Calibration accuracy
    """
    print("=" * 80)
    print("ENHANCED CLASS-LEVEL DISCOVERY EXPERIMENTS")
    print("=" * 80)

    harmonizer = StringHarmonizer(quiet=True)
    composer = EnhancedClassComposer()

    # Analyze method library
    print("\n[STEP 1] Analyzing Method Library")
    print("-" * 80)

    method_profiles = {}
    for name, source in METHOD_LIBRARY.items():
        print(f"  Analyzing '{name}'...")
        report = harmonizer.analyze_file_content(source)

        if report:
            func_name = list(report.keys())[0]
            coords = report[func_name]["ice_result"]["ice_components"]["intent"].coordinates
            profile = LJPWProfile(L=coords.love, J=coords.justice, P=coords.power, W=coords.wisdom)
            method_profiles[name] = profile
            print(f"    -> {profile}")
        else:
            method_profiles[name] = LJPWProfile(0, 0, 0, 0)

    # Initialize engines
    rule_engine = EnhancedCompositionRules(method_profiles)
    discovery_engine = ClassDiscoveryEngine(
        method_profiles=method_profiles,
        rule_engine=rule_engine,
        available_methods=list(METHOD_LIBRARY.keys()),
    )

    # Experiment 1: Discovery with specific targets
    print("\n" + "=" * 80)
    print("EXPERIMENT 1: Targeted Class Discovery")
    print("=" * 80)

    test_targets = [
        {
            "name": "High Justice Calculator",
            "profile": LJPWProfile(L=0.4, J=0.9, P=0.5, W=0.6),
            "description": "Emphasis on correctness and validation",
        },
        {
            "name": "High Love Calculator",
            "profile": LJPWProfile(L=0.95, J=0.6, P=0.5, W=0.7),
            "description": "Emphasis on observability and user experience",
        },
        {
            "name": "Balanced Calculator",
            "profile": LJPWProfile(L=0.7, J=0.7, P=0.5, W=0.8),
            "description": "Well-rounded with high wisdom",
        },
        {
            "name": "Minimal Power Calculator",
            "profile": LJPWProfile(L=0.6, J=0.6, P=0.3, W=0.5),
            "description": "Simple, basic functionality",
        },
    ]

    for target_spec in test_targets:
        print(f"\n{'='*80}")
        print(f"Target: {target_spec['name']}")
        print(f"Profile: {target_spec['profile']}")
        print(f"Description: {target_spec['description']}")
        print("=" * 80)

        results = discovery_engine.search(
            target_profile=target_spec["profile"],
            min_methods=2,
            max_methods=5,
            allow_structural_features=True,
            top_k=3,
        )

        print("\nTop 3 Discovered Designs:")
        for i, (structure, predicted, distance) in enumerate(results, 1):
            print(f"\n{i}. {structure}")
            print(f"   Predicted: {predicted}")
            print(f"   Distance:  {distance:.4f}")

            # Generate and save top result
            if i == 1:
                class_name = target_spec["name"].replace(" ", "")
                class_code = composer.generate_class(
                    name=class_name, structure=structure, method_sources=METHOD_LIBRARY
                )
                filename = f"discovered_{class_name}.py"
                with open(filename, "w") as f:
                    f.write(class_code)
                print(f"   -> Saved to {filename}")

    # Experiment 2: Structural feature impact
    print("\n" + "=" * 80)
    print("EXPERIMENT 2: Structural Feature Impact Analysis")
    print("=" * 80)

    base_methods = ["secure_add", "secure_subtract", "secure_multiply"]

    test_structures = [
        ClassStructure(methods=base_methods),
        ClassStructure(methods=base_methods, has_state=True, has_init=True),
        ClassStructure(methods=base_methods, has_history=True, has_init=True),
        ClassStructure(methods=base_methods, has_properties=True),
        ClassStructure(
            methods=base_methods,
            has_state=True,
            has_history=True,
            has_properties=True,
            has_init=True,
        ),
    ]

    print("\nStructural Feature Impact:")
    print(f"{'Structure':<40} {'Predicted Profile':<40} {'Complexity'}")
    print("-" * 80)

    for structure in test_structures:
        predicted = rule_engine.predict_profile(structure)
        complexity = structure.structural_complexity()
        print(f"{str(structure):<40} {str(predicted):<40} {complexity}")

    # Experiment 3: Calibration
    if HARMONIZER_AVAILABLE:
        print("\n" + "=" * 80)
        print("EXPERIMENT 3: Calibration Analysis")
        print("=" * 80)

        calibration_fw = CalibrationFramework(composer, harmonizer)
        calibration_results = calibration_fw.calibrate(
            test_structures=test_structures, method_sources=METHOD_LIBRARY, rule_engine=rule_engine
        )

        print(
            f"\nCalibration complete. Average error: {calibration_results.get('avg_error', 'N/A')}"
        )
    else:
        print("\n[Skipping calibration - real harmonizer not available]")

    print("\n" + "=" * 80)
    print("EXPERIMENTS COMPLETE")
    print("=" * 80)

    print("\nKey Findings:")
    print("1. Discovery successfully finds different structures for different targets")
    print("2. Structural features predictably affect LJPW dimensions")
    print("3. Class-level discovery mirrors function-level discovery patterns")
    print("4. Same semantic principles apply at multiple abstraction levels")

    print("\nNext Steps:")
    print("- Fine-tune calibration coefficients")
    print("- Test inheritance and composition patterns")
    print("- Validate with real-world code examples")
    print("- Scale to Level 3 (Classes â†’ Modules)")


if __name__ == "__main__":
    run_enhanced_experiments()
